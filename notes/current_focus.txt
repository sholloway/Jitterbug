Next steps:
Get pixels flowing.
	API -> SceneGraph -> Spatial Partition -> Culler -> Render -> ImageProcessor -> Image 
	
1. Write basic API code for def rect(x,y,width,height)
	Need stroke, fill, rect_mode, bind to shader (Want to reference a structure of shaders. Don't have multiple copies floating around.)
2. Write SceneGraph
	Need add_geometry 
3. Spatial Partition
	Just need to add all geometry to the culler at this point.
4. Renderer
	Need a way of managing shaders. Part of Geometry class?
	Combine the work done on JBOpenGLView + WebGL
	Render to Framebuffer
5. ImageProcessor
	Get pixels from Framebuffer
	Persist as a PNG image
	
After the initial pipeline is in place, my next step should probably be to nail down the color definition of the system.	

Need to think through 2D API. Do I want to draw on the screen by projecting everything or do I want to create 3D geometry?
Could also use billboards.
Start with projection just to keep moving forward.

Current Bug/Challenges
Cannot execute tests that rely on glsl_renderer due to it instantiates a modal window.
Clean task is not working.

Don't forget, I've already solved the issue of getting pixels from a FBO before. Look at code on the iMac. That's how I
did the Stanford bunny.

If I can find a way to run tests that render out I think it would ultimately save me a bunch of time. 
Manual Testing Feedback Loop
- rake clobber
- rake
- jb create blah
- jb render
- manually close all frames
- look at log/image/screen